This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: genbase/server/src
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)


================================================================
Directory Structure
================================================================
genbase/
  server/
    src/
      routers/
        __Init__.py
        chat.py
        code.py
        groups.py
        operations.py
        projects.py
        variables.py
        workspaces.py
      schemas/
        api.py
      services/
        __init__.py
        chat_service.py
        code_service.py
        git_service.py
        group_service.py
        project_service.py
        tf_service.py
        variable_service.py
        workspace_service.py
      config.py
      database.py
      logger.py
      main.py
      models.py

================================================================
Files
================================================================

================
File: genbase/server/src/routers/chat.py
================
"""
FastAPI router for chat operations
"""
from fastapi import APIRouter, HTTPException, Path as PathParam, Body, Query
from pydantic import BaseModel
from typing import Optional, List, Dict, Any

from src.schemas.api import ChatSessionResponse, ChatSessionListResponse, ChatMessageResponse, ChatMessageListResponse
from ..logger import logger
from ..services.project_service import ProjectService
from ..services.chat_service import ChatService


# Request models
class CreateChatSessionRequest(BaseModel):
    """Create chat session request"""
    title: Optional[str] = None



class SendMessageRequest(BaseModel):
    """Send message request"""
    session_id: str
    content: str



router = APIRouter(
    prefix="/projects/{project_id}/chat",
    tags=["chat"]
)


@router.post("/sessions", response_model=ChatSessionResponse)
async def create_chat_session(
    request: CreateChatSessionRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """
    Create a new chat session
    
    Creates a new chat session with a corresponding Git branch.
    The branch name follows the pattern: user/default/{session_number}
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        result = ChatService.create_chat_session(project_id, request.title)
        
        if not result.get("success", False):
            return ChatSessionResponse(
                success=False,
                message="Failed to create chat session",
                data={"error": result.get("error", "Unknown error")}
            )
        
        return ChatSessionResponse(
            success=True,
            message=result.get("message", "Chat session created successfully"),
            data=result.get("session", {})
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating chat session: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions", response_model=ChatSessionListResponse)
async def list_chat_sessions(
    project_id: str = PathParam(..., title="Project ID")
):
    """
    List all chat sessions for a project
    
    Returns all chat sessions with metadata including message counts,
    last activity, and Git branch information.
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        sessions = ChatService.list_chat_sessions(project_id)
        
        return ChatSessionListResponse(
            success=True,
            message=f"Found {len(sessions)} chat sessions",
            data=sessions
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing chat sessions: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/sessions", response_model=ChatSessionResponse)
async def delete_chat_session(
    project_id: str = PathParam(..., title="Project ID"),
    session_id: str = Query(..., title="Session ID to delete")
):
    """
    Delete a chat session
    
    Deletes the chat session, all its messages, and the corresponding Git branch.
    This action cannot be undone.
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        result = ChatService.delete_chat_session(project_id, session_id)
        
        if not result.get("success", False):
            return ChatSessionResponse(
                success=False,
                message="Failed to delete chat session",
                data={"error": result.get("error", "Unknown error")}
            )
        
        return ChatSessionResponse(
            success=True,
            message=result.get("message", "Chat session deleted successfully"),
            data={"deleted_messages": result.get("deleted_messages", 0)}
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting chat session: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/messages", response_model=ChatMessageResponse)
async def send_message(
    request: SendMessageRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """
    Send a user message to a chat session
    
    Adds a user message to the specified chat session.
    The session_id is provided in the request body to avoid URL encoding issues.
    This will handle any pending tool calls automatically.
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        result = ChatService.add_user_message(project_id, request.session_id, request.content)
        
        if not result.get("success", False):
            return ChatMessageResponse(
                success=False,
                message="Failed to send message",
                data={"error": result.get("error", "Unknown error")}
            )
        
        return ChatMessageResponse(
            success=True,
            message=result.get("message", "Message sent successfully"),
            data=result.get("message_data", {})
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error sending message: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/messages", response_model=ChatMessageListResponse)
async def get_messages(
    project_id: str = PathParam(..., title="Project ID"),
    session_id: str = Query(..., title="Session ID")
):
    """
    Get all messages in a chat session
    
    Returns all messages in the chat session in LiteLLM format,
    ordered by creation time. The session_id is provided as a query parameter.
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        messages = ChatService.get_messages(project_id, session_id)
        
        return ChatMessageListResponse(
            success=True,
            message=f"Retrieved {len(messages)} messages",
            data=messages
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting messages: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: genbase/server/src/routers/code.py
================
"""
FastAPI router for code operations
"""
from pathlib import Path
from fastapi import APIRouter, HTTPException, Path as PathParam, Query
from typing import Optional

from src.schemas.api import CodeResponse, CodeStructureResponse
from ..logger import logger
from ..services.project_service import ProjectService
from ..services.code_service import CodeService


router = APIRouter(
    prefix="/projects/{project_id}/code",
    tags=["code"]
)


@router.get("/", response_model=CodeResponse)
async def parse_project_code(
    project_id: str = PathParam(..., title="Project ID")
):
    """
    Parse all Terraform files in the project and return structured configuration
    
    This endpoint reads all .tf files in the project, converts them to JSON format,
    and adds metadata (group path and file name) to each configuration block.
    All configurations are then combined into a single structured response.
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        result = CodeService.parse_project_code(project_id)
        
        if not result.get("success", False):
            return CodeResponse(
                success=False,
                message="Failed to parse project code",
                data={"error": result.get("error", "Unknown error")}
            )
        
        return CodeResponse(
            success=True,
            message="Project code parsed successfully",
            data=result.get("data", {})
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error parsing project code: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))




@router.get("/files", response_model=CodeResponse)
async def list_terraform_files(
    project_id: str = PathParam(..., title="Project ID")
):
    """
    List all Terraform files in the project with their paths
    
    This endpoint returns a list of all .tf files found in the project,
    organized by their group paths.
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        try:
            tf_files = CodeService.get_all_tf_files(project_id)
            infra_path = ProjectService.get_infrastructure_path(project_id)
            
            # Organize files by group
            files_by_group = {}
            
            for tf_file in tf_files:
                rel_path = tf_file.relative_to(infra_path)
                group_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""
                
                if group_path not in files_by_group:
                    files_by_group[group_path] = []
                
                files_by_group[group_path].append({
                    "file_name": tf_file.stem,
                    "full_path": str(rel_path)
                })
            
            return CodeResponse(
                success=True,
                message=f"Found {len(tf_files)} Terraform files",
                data={
                    "project_id": project_id,
                    "total_files": len(tf_files),
                    "files_by_group": files_by_group
                }
            )
            
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing Terraform files: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: genbase/server/src/services/chat_service.py
================
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import desc, asc

from ..database import get_db
from ..models import ChatMessage
from ..logger import logger
from .project_service import ProjectService
from .git_service import GitService


class ChatService:
    """
    Service for managing AI chat sessions
    
    Each chat session corresponds to a Git branch but we handle
    branch operations virtually to avoid conflicts during concurrent access.
    """
    
    DEFAULT_USER_ID = "default"
    
    @staticmethod
    def create_chat_session(project_id: str, title: Optional[str] = None) -> Dict[str, Any]:
        """
        Create a new chat session with corresponding Git branch
        
        Args:
            project_id: The project identifier
            title: Optional title for the chat session (not stored, just returned)
            
        Returns:
            Dictionary with session information
        """
        try:
            # Check if project exists
            project = ProjectService.get_project(project_id)
            if not project:
                return {
                    "success": False,
                    "error": f"Project not found: {project_id}"
                }
            
            # Get existing chat branches to determine next session number
            chat_branches = GitService.list_chat_branches(project_id)
            next_session_number = 1
            
            if chat_branches:
                # Get the highest session number and add 1
                max_session = max(branch["session_number"] for branch in chat_branches)
                next_session_number = max_session + 1
            
            # Create branch name
            user_id = ChatService.DEFAULT_USER_ID
            branch_name = f"user/{user_id}/{next_session_number}"
            
            # Initialize Git repository if not already initialized
            GitService.init_repository(project_id)
            
            # Create Git branch (this will create it from main but not switch to it)
            git_result = GitService.create_branch(project_id, branch_name)
            if not git_result.get("success", False):
                return {
                    "success": False,
                    "error": f"Failed to create Git branch: {git_result.get('error', 'Unknown error')}"
                }
            
            logger.info(f"Created chat session {branch_name} for project {project_id}")
            
            return {
                "success": True,
                "message": "Chat session created successfully",
                "session": {
                    "session_id": branch_name,
                    "session_number": next_session_number,
                    "title": title or f"Chat Session {next_session_number}",
                    "project_id": project_id,
                    "created_at": datetime.now().isoformat(),
                    "message_count": 0
                }
            }
            
        except Exception as e:
            logger.error(f"Error creating chat session: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def list_chat_sessions(project_id: str) -> List[Dict[str, Any]]:
        """
        List all chat sessions for a project
        
        Args:
            project_id: The project identifier
            
        Returns:
            List of chat session information
        """
        try:
            # Check if project exists
            project = ProjectService.get_project(project_id)
            if not project:
                raise ValueError(f"Project not found: {project_id}")
            
            # Get chat branches from Git
            chat_branches = GitService.list_chat_branches(project_id)
            
            # Get database session
            db: Session = next(get_db())
            
            sessions = []
            
            for branch in chat_branches:
                branch_name = branch["branch_name"]
                
                # Get message count for this session
                message_count = db.query(ChatMessage)\
                    .filter(ChatMessage.project_id == project_id)\
                    .filter(ChatMessage.session_id == branch_name)\
                    .count()
                
                # Get last message timestamp
                last_message = db.query(ChatMessage)\
                    .filter(ChatMessage.project_id == project_id)\
                    .filter(ChatMessage.session_id == branch_name)\
                    .order_by(desc(ChatMessage.created_at))\
                    .first()
                
                last_message_at = None
                if last_message:
                    last_message_at = last_message.created_at.isoformat()
                elif branch["last_commit_date"]:
                    # Use Git commit date as fallback
                    last_message_at = branch["last_commit_date"]
                
                sessions.append({
                    "session_id": branch_name,
                    "session_number": branch["session_number"],
                    "title": f"Chat Session {branch['session_number']}",
                    "project_id": project_id,
                    "message_count": message_count,
                    "last_message_at": last_message_at,
                    "last_commit_date": branch["last_commit_date"],
                    "last_commit_message": branch["last_commit_message"]
                })
            
            db.close()
            
            return sessions
            
        except Exception as e:
            logger.error(f"Error listing chat sessions: {str(e)}")
            return []
    
    @staticmethod
    def delete_chat_session(project_id: str, session_id: str) -> Dict[str, Any]:
        """
        Delete a chat session and its Git branch
        
        Args:
            project_id: The project identifier
            session_id: The session identifier (branch name)
            
        Returns:
            Dictionary with success status
        """
        try:
            # Check if project exists
            project = ProjectService.get_project(project_id)
            if not project:
                return {
                    "success": False,
                    "error": f"Project not found: {project_id}"
                }
            
            # Get database session
            db: Session = next(get_db())
            
            try:
                # Delete all messages for this session
                deleted_count = db.query(ChatMessage)\
                    .filter(ChatMessage.project_id == project_id)\
                    .filter(ChatMessage.session_id == session_id)\
                    .delete()
                
                db.commit()
                
                # Delete Git branch
                git_result = GitService.delete_branch(project_id, session_id)
                
                if not git_result.get("success", False):
                    # Rollback message deletion if Git delete failed
                    db.rollback()
                    return {
                        "success": False,
                        "error": f"Failed to delete Git branch: {git_result.get('error', 'Unknown error')}"
                    }
                
                logger.info(f"Deleted chat session {session_id} with {deleted_count} messages")
                
                return {
                    "success": True,
                    "message": f"Chat session deleted successfully",
                    "deleted_messages": deleted_count
                }
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"Error deleting chat session: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def add_user_message(project_id: str, session_id: str, content: str) -> Dict[str, Any]:
        """
        Add a user message to a chat session
        
        Args:
            project_id: The project identifier
            session_id: The session identifier (branch name)
            content: Message content
            
        Returns:
            Dictionary with message information
        """
        try:
            return ChatService._add_message(
                project_id=project_id,
                session_id=session_id,
                role="user",
                content=content
            )
            
        except Exception as e:
            logger.error(f"Error adding user message: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def add_agent_message(
        project_id: str, 
        session_id: str, 
        content: Optional[str] = None,
        tool_calls: Optional[List[Dict[str, Any]]] = None,
        reasoning_content: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Add an agent (assistant) message to a chat session
        
        Args:
            project_id: The project identifier
            session_id: The session identifier (branch name)
            content: Message content
            tool_calls: Tool calls made by the agent
            reasoning_content: Reasoning content for o1 models
            
        Returns:
            Dictionary with message information
        """
        try:
            return ChatService._add_message(
                project_id=project_id,
                session_id=session_id,
                role="assistant",
                content=content,
                tool_calls=tool_calls,
                reasoning_content=reasoning_content
            )
            
        except Exception as e:
            logger.error(f"Error adding agent message: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def add_tool_result(
        project_id: str, 
        session_id: str,
        tool_call_id: str,
        name: str,
        content: str
    ) -> Dict[str, Any]:
        """
        Add a tool result message to a chat session
        
        Args:
            project_id: The project identifier
            session_id: The session identifier (branch name)
            tool_call_id: ID of the tool call this is responding to
            name: Name of the tool
            content: Tool execution result
            
        Returns:
            Dictionary with message information
        """
        try:
            return ChatService._add_message(
                project_id=project_id,
                session_id=session_id,
                role="tool",
                content=content,
                tool_call_id=tool_call_id,
                name=name
            )
            
        except Exception as e:
            logger.error(f"Error adding tool result: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def _add_message(
        project_id: str,
        session_id: str,
        role: str,
        content: Optional[str] = None,
        tool_calls: Optional[List[Dict[str, Any]]] = None,
        tool_call_id: Optional[str] = None,
        name: Optional[str] = None,
        reasoning_content: Optional[str] = None,
        annotations: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """
        Internal method to add a message to a chat session
        """
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            return {
                "success": False,
                "error": f"Project not found: {project_id}"
            }
        
        # Verify that the session exists by checking if branch exists
        chat_branches = GitService.list_chat_branches(project_id)
        branch_exists = any(branch["branch_name"] == session_id for branch in chat_branches)
        
        if not branch_exists:
            return {
                "success": False,
                "error": f"Chat session not found: {session_id}"
            }
        
        # Get database session
        db: Session = next(get_db())
        
        try:
            # Handle tool call validation
            if role != "tool":
                # Check for pending tool calls that need responses
                ChatService._handle_pending_tool_calls(db, project_id, session_id)
            
            # Create new message
            message = ChatMessage(
                project_id=project_id,
                session_id=session_id,
                role=role,
                content=content,
                tool_calls=tool_calls,
                tool_call_id=tool_call_id,
                name=name,
                reasoning_content=reasoning_content,
                annotations=annotations
            )
            
            db.add(message)
            db.commit()
            db.refresh(message)
            
            logger.info(f"Added {role} message to session {session_id}")
            
            return {
                "success": True,
                "message": "Message added successfully",
                "message_data": {
                    "id": message.id,
                    "role": message.role,
                    "content": message.content,
                    "created_at": message.created_at.isoformat(),
                    "litellm_format": message.to_litellm_format()
                }
            }
            
        finally:
            db.close()
    
    @staticmethod
    def _handle_pending_tool_calls(db: Session, project_id: str, session_id: str):
        """
        Handle pending tool calls by adding failed responses if missing
        """
        # Get the last assistant message with tool calls
        last_assistant_msg = db.query(ChatMessage)\
            .filter(ChatMessage.project_id == project_id)\
            .filter(ChatMessage.session_id == session_id)\
            .filter(ChatMessage.role == "assistant")\
            .filter(ChatMessage.tool_calls.isnot(None))\
            .order_by(desc(ChatMessage.created_at))\
            .first()
        
        if not last_assistant_msg or last_assistant_msg.tool_calls is None:
            return
        
        # Get all tool call IDs from the last assistant message
        tool_call_ids = [call["id"] for call in last_assistant_msg.tool_calls if "id" in call]
        
        if not tool_call_ids:
            return
        
        # Check which tool calls already have responses
        existing_responses = db.query(ChatMessage.tool_call_id)\
            .filter(ChatMessage.project_id == project_id)\
            .filter(ChatMessage.session_id == session_id)\
            .filter(ChatMessage.role == "tool")\
            .filter(ChatMessage.tool_call_id.in_(tool_call_ids))\
            .filter(ChatMessage.created_at > last_assistant_msg.created_at)\
            .all()
        
        existing_tool_call_ids = [response.tool_call_id for response in existing_responses]
        
        # Add failed responses for missing tool calls
        for tool_call in last_assistant_msg.tool_calls:
            if tool_call.get("id") not in existing_tool_call_ids:
                failed_message = ChatMessage(
                    project_id=project_id,
                    session_id=session_id,
                    role="tool",
                    content="Tool call failed",
                    tool_call_id=tool_call.get("id"),
                    name=tool_call.get("function", {}).get("name", "unknown")
                )
                db.add(failed_message)
        
        db.commit()
    
    @staticmethod
    def get_messages(project_id: str, session_id: str) -> List[Dict[str, Any]]:
        """
        Get all messages in a chat session in LiteLLM format
        
        Args:
            project_id: The project identifier
            session_id: The session identifier (branch name)
            
        Returns:
            List of messages in LiteLLM format
        """
        try:
            # Check if project exists
            project = ProjectService.get_project(project_id)
            if not project:
                raise ValueError(f"Project not found: {project_id}")
            
            # Verify that the session exists
            chat_branches = GitService.list_chat_branches(project_id)
            branch_exists = any(branch["branch_name"] == session_id for branch in chat_branches)
            
            if not branch_exists:
                raise ValueError(f"Chat session not found: {session_id}")
            
            # Get database session
            db: Session = next(get_db())
            
            try:
                # Get all messages for this session, ordered by creation time
                messages = db.query(ChatMessage)\
                    .filter(ChatMessage.project_id == project_id)\
                    .filter(ChatMessage.session_id == session_id)\
                    .order_by(asc(ChatMessage.created_at))\
                    .all()
                
                # Convert to LiteLLM format
                litellm_messages = [message.to_litellm_format() for message in messages]
                
                return litellm_messages
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"Error getting messages: {str(e)}")
            return []

================
File: genbase/server/src/services/code_service.py
================
"""
Service for reading and processing Terraform code files
"""
import json
import os
import hcl2
from glob import glob
from pathlib import Path
from typing import Dict, List, Any, Optional

from ..logger import logger
from .project_service import ProjectService
from .group_service import GroupService


class CodeService:
    """
    Service for reading, parsing, and structuring Terraform code files
    """
    
    @staticmethod
    def _parse_tf_file(file_path: Path, infra_path: Path) -> Dict[str, Any]:
        """
        Parse a single .tf file and extract its configuration
        
        Args:
            file_path: Path to the .tf file
            infra_path: Base infrastructure path for calculating relative paths
            
        Returns:
            Dictionary containing parsed configuration with metadata
        """
        try:
            with open(file_path, 'r') as file:
                tf_content = hcl2.api.load(file)
            
            # Calculate group path and file name
            rel_path = file_path.relative_to(infra_path)
            group_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""
            file_name = file_path.stem  # filename without extension
            
            # Add metadata to all top-level blocks
            processed_content = {}
            
            for block_type, blocks in tf_content.items():
                processed_content[block_type] = []
                
                # Handle different block types
                if block_type == "resource":
                    processed_content[block_type] = CodeService._process_resource_blocks(
                        blocks, group_path, file_name
                    )
                elif block_type == "module":
                    processed_content[block_type] = CodeService._process_module_blocks(
                        blocks, group_path, file_name
                    )
                elif block_type == "data":
                    processed_content[block_type] = CodeService._process_data_blocks(
                        blocks, group_path, file_name
                    )
                elif block_type == "output":
                    processed_content[block_type] = CodeService._process_output_blocks(
                        blocks, group_path, file_name
                    )
                elif block_type == "variable":
                    processed_content[block_type] = CodeService._process_variable_blocks(
                        blocks, group_path, file_name
                    )
                elif block_type == "locals":
                    processed_content[block_type] = CodeService._process_locals_blocks(
                        blocks, group_path, file_name
                    )
                elif block_type == "provider":
                    processed_content[block_type] = CodeService._process_provider_blocks(
                        blocks, group_path, file_name
                    )
                elif block_type == "terraform":
                    processed_content[block_type] = CodeService._process_terraform_blocks(
                        blocks, group_path, file_name
                    )
                else:
                    # For unknown block types, just add metadata
                    processed_content[block_type] = CodeService._add_metadata_to_blocks(
                        blocks, block_type, group_path, file_name
                    )
            
            return processed_content
            
        except Exception as e:
            logger.error(f"Error parsing Terraform file {file_path}: {str(e)}")
            return {
                "_error": {
                    "message": str(e),
                    "group_path": str(file_path.relative_to(infra_path).parent) if file_path.relative_to(infra_path).parent != Path(".") else "",
                    "file_name": file_path.stem
                }
            }
    
    @staticmethod
    def _process_resource_blocks(blocks: Any, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Process resource blocks with metadata"""
        result = []
        
        # Handle different HCL2 parser output formats
        if isinstance(blocks, list):
            for block_dict in blocks:
                for resource_type, resource_instances in block_dict.items():
                    if isinstance(resource_instances, dict):
                        for resource_name, resource_config in resource_instances.items():
                            result.append({
                                "type": resource_type,
                                "name": resource_name,
                                "address": f"{resource_type}.{resource_name}",
                                "config": resource_config,
                                "_metadata": {
                                    "group_path": group_path,
                                    "file_name": file_name,
                                    "block_type": "resource"
                                }
                            })
        elif isinstance(blocks, dict):
            for resource_type, resource_instances in blocks.items():
                if isinstance(resource_instances, dict):
                    for resource_name, resource_config in resource_instances.items():
                        result.append({
                            "type": resource_type,
                            "name": resource_name,
                            "address": f"{resource_type}.{resource_name}",
                            "config": resource_config,
                            "_metadata": {
                                "group_path": group_path,
                                "file_name": file_name,
                                "block_type": "resource"
                            }
                        })
        
        return result
    
    @staticmethod
    def _process_module_blocks(blocks: Any, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Process module blocks with metadata"""
        result = []
        
        if isinstance(blocks, list):
            for block_dict in blocks:
                for module_name, module_config in block_dict.items():
                    result.append({
                        "name": module_name,
                        "address": f"module.{module_name}",
                        "config": module_config,
                        "_metadata": {
                            "group_path": group_path,
                            "file_name": file_name,
                            "block_type": "module"
                        }
                    })
        elif isinstance(blocks, dict):
            for module_name, module_config in blocks.items():
                result.append({
                    "name": module_name,
                    "address": f"module.{module_name}",
                    "config": module_config,
                    "_metadata": {
                        "group_path": group_path,
                        "file_name": file_name,
                        "block_type": "module"
                    }
                })
        
        return result
    
    @staticmethod
    def _process_data_blocks(blocks: Any, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Process data blocks with metadata"""
        result = []
        
        if isinstance(blocks, list):
            for block_dict in blocks:
                for data_type, data_instances in block_dict.items():
                    if isinstance(data_instances, dict):
                        for data_name, data_config in data_instances.items():
                            result.append({
                                "type": data_type,
                                "name": data_name,
                                "address": f"data.{data_type}.{data_name}",
                                "config": data_config,
                                "_metadata": {
                                    "group_path": group_path,
                                    "file_name": file_name,
                                    "block_type": "data"
                                }
                            })
        elif isinstance(blocks, dict):
            for data_type, data_instances in blocks.items():
                if isinstance(data_instances, dict):
                    for data_name, data_config in data_instances.items():
                        result.append({
                            "type": data_type,
                            "name": data_name,
                            "address": f"data.{data_type}.{data_name}",
                            "config": data_config,
                            "_metadata": {
                                "group_path": group_path,
                                "file_name": file_name,
                                "block_type": "data"
                            }
                        })
        
        return result
    
    @staticmethod
    def _process_output_blocks(blocks: Any, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Process output blocks with metadata"""
        result = []
        
        if isinstance(blocks, list):
            for block_dict in blocks:
                for output_name, output_config in block_dict.items():
                    result.append({
                        "name": output_name,
                        "config": output_config,
                        "_metadata": {
                            "group_path": group_path,
                            "file_name": file_name,
                            "block_type": "output"
                        }
                    })
        elif isinstance(blocks, dict):
            for output_name, output_config in blocks.items():
                result.append({
                    "name": output_name,
                    "config": output_config,
                    "_metadata": {
                        "group_path": group_path,
                        "file_name": file_name,
                        "block_type": "output"
                    }
                })
        
        return result
    
    @staticmethod
    def _process_variable_blocks(blocks: Any, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Process variable blocks with metadata"""
        result = []
        
        if isinstance(blocks, list):
            for block_dict in blocks:
                for var_name, var_config in block_dict.items():
                    result.append({
                        "name": var_name,
                        "config": var_config,
                        "_metadata": {
                            "group_path": group_path,
                            "file_name": file_name,
                            "block_type": "variable"
                        }
                    })
        elif isinstance(blocks, dict):
            for var_name, var_config in blocks.items():
                result.append({
                    "name": var_name,
                    "config": var_config,
                    "_metadata": {
                        "group_path": group_path,
                        "file_name": file_name,
                        "block_type": "variable"
                    }
                })
        
        return result
    
    @staticmethod
    def _process_locals_blocks(blocks: Any, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Process locals blocks with metadata"""
        result = []
        
        if isinstance(blocks, list):
            for locals_block in blocks:
                result.append({
                    "config": locals_block,
                    "_metadata": {
                        "group_path": group_path,
                        "file_name": file_name,
                        "block_type": "locals"
                    }
                })
        elif isinstance(blocks, dict):
            result.append({
                "config": blocks,
                "_metadata": {
                    "group_path": group_path,
                    "file_name": file_name,
                    "block_type": "locals"
                }
            })
        
        return result
    
    @staticmethod
    def _process_provider_blocks(blocks: Any, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Process provider blocks with metadata"""
        result = []
        
        if isinstance(blocks, list):
            for block_dict in blocks:
                for provider_name, provider_config in block_dict.items():
                    result.append({
                        "name": provider_name,
                        "config": provider_config,
                        "_metadata": {
                            "group_path": group_path,
                            "file_name": file_name,
                            "block_type": "provider"
                        }
                    })
        elif isinstance(blocks, dict):
            for provider_name, provider_config in blocks.items():
                result.append({
                    "name": provider_name,
                    "config": provider_config,
                    "_metadata": {
                        "group_path": group_path,
                        "file_name": file_name,
                        "block_type": "provider"
                    }
                })
        
        return result
    
    @staticmethod
    def _process_terraform_blocks(blocks: Any, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Process terraform blocks with metadata"""
        result = []
        
        if isinstance(blocks, list):
            for terraform_block in blocks:
                result.append({
                    "config": terraform_block,
                    "_metadata": {
                        "group_path": group_path,
                        "file_name": file_name,
                        "block_type": "terraform"
                    }
                })
        elif isinstance(blocks, dict):
            result.append({
                "config": blocks,
                "_metadata": {
                    "group_path": group_path,
                    "file_name": file_name,
                    "block_type": "terraform"
                }
            })
        
        return result
    
    @staticmethod
    def _add_metadata_to_blocks(blocks: Any, block_type: str, group_path: str, file_name: str) -> List[Dict[str, Any]]:
        """Add metadata to unknown block types"""
        result = []
        
        if isinstance(blocks, list):
            for block in blocks:
                result.append({
                    "config": block,
                    "_metadata": {
                        "group_path": group_path,
                        "file_name": file_name,
                        "block_type": block_type
                    }
                })
        else:
            result.append({
                "config": blocks,
                "_metadata": {
                    "group_path": group_path,
                    "file_name": file_name,
                    "block_type": block_type
                }
            })
        
        return result
    
    @staticmethod
    def get_all_tf_files(project_id: str) -> List[Path]:
        """
        Get all .tf files in the project, excluding ignored directories
        """
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            raise ValueError(f"Infrastructure directory not found for project: {project_id}")
        
        tf_files = []
        
        # Walk through the directory structure
        for root, dirs, files in os.walk(infra_path):
            # Remove ignored directories from dirs to prevent walking into them
            dirs[:] = [d for d in dirs if d not in GroupService.IGNORED_DIRECTORIES]
            
            # Add .tf files from current directory
            for file in files:
                if file.endswith('.tf'):
                    tf_files.append(Path(root) / file)
        
        return tf_files
    
    @staticmethod
    def parse_project_code(project_id: str) -> Dict[str, Any]:
        """
        Parse all Terraform files in a project and return combined configuration
        
        Returns:
            Dictionary with all parsed configurations combined
        """
        try:
            # Get infrastructure path
            infra_path = ProjectService.get_infrastructure_path(project_id)
            
            # Get all .tf files
            tf_files = CodeService.get_all_tf_files(project_id)
            
            if not tf_files:
                logger.warning(f"No .tf files found in project: {project_id}")
                return {
                    "success": True,
                    "data": {
                        "project_id": project_id,
                        "files_processed": 0,
                        "blocks": {}
                    }
                }
            
            # Combined configuration
            combined_config = {
                "resource": [],
                "module": [],
                "data": [],
                "output": [],
                "variable": [],
                "locals": [],
                "provider": [],
                "terraform": []
            }
            
            files_processed = 0
            parse_errors = []
            
            # Process each file
            for tf_file in tf_files:
                try:
                    parsed_content = CodeService._parse_tf_file(tf_file, infra_path)
                    
                    # Add to combined configuration
                    for block_type, blocks in parsed_content.items():
                        if block_type == "_error":
                            parse_errors.append(blocks)
                            continue
                            
                        if block_type not in combined_config:
                            combined_config[block_type] = []
                        
                        combined_config[block_type].extend(blocks)
                    
                    files_processed += 1
                    
                except Exception as e:
                    logger.error(f"Error processing file {tf_file}: {str(e)}")
                    parse_errors.append({
                        "file": str(tf_file.relative_to(infra_path)),
                        "error": str(e)
                    })
            
            # Remove empty block types
            combined_config = {k: v for k, v in combined_config.items() if v}
            
            result = {
                "project_id": project_id,
                "files_processed": files_processed,
                "total_files": len(tf_files),
                "blocks": combined_config
            }
            
            if parse_errors:
                result["parse_errors"] = parse_errors
            
            return {
                "success": True,
                "data": result
            }
            
        except Exception as e:
            logger.error(f"Error parsing project code: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

================
File: genbase/server/src/services/git_service.py
================
"""
Simplified Git service for managing repository operations using GitPython
"""
import os
from pathlib import Path
from typing import List, Dict, Any, Optional
from git import Repo, InvalidGitRepositoryError

from ..logger import logger
from .project_service import ProjectService


class GitService:
    """
    Simplified service for managing Git operations for projects
    """
    
    @staticmethod
    def init_repository(project_id: str) -> Dict[str, Any]:
        """Initialize a Git repository for a project"""
        try:
            project_path = ProjectService.get_project_path(project_id)
            
            # Check if already a git repository
            if GitService._is_git_repository(project_path):
                repo = Repo(project_path)
                return {
                    "success": True,
                    "message": "Repository already initialized",
                    "already_exists": True,
                    "branch": repo.active_branch.name
                }
            
            # Initialize repository
            repo = Repo.init(project_path)
            
            # Create .gitignore
            gitignore_path = project_path / ".gitignore"
            if not gitignore_path.exists():
                gitignore_content = """# Terraform files
.terraform/
*.tfstate
*.tfstate.backup
*.tfplan
*.auto.tfvars.json

# Logs
*.log
"""
                with open(gitignore_path, 'w') as f:
                    f.write(gitignore_content)
            
            # Initial commit (this creates the first branch)
            repo.git.add(A=True)
            repo.index.commit("Initial commit")
            
            # Ensure we're on main branch (in case it was created as master)
            current_branch = repo.active_branch.name
            if current_branch != "main":
                # Rename the branch to main
                repo.git.branch('-m', current_branch, 'main')
            
            logger.info(f"Git repository initialized for project: {project_id} on main branch")
            
            return {
                "success": True,
                "message": "Repository initialized successfully",
                "already_exists": False,
                "branch": "main"
            }
            
        except Exception as e:
            logger.error(f"Error initializing Git repository: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
        


    @staticmethod
    def _is_git_repository(path: Path) -> bool:
        """Check if directory is a Git repository"""
        try:
            Repo(path)
            return True
        except InvalidGitRepositoryError:
            return False
    
    @staticmethod
    def get_repository(project_id: str) -> Optional[Repo]:
        """Get Git repository object for a project"""
        try:
            project_path = ProjectService.get_project_path(project_id)
            return Repo(project_path)
        except InvalidGitRepositoryError:
            return None
    
    @staticmethod
    def create_branch(project_id: str, branch_name: str) -> Dict[str, Any]:
        """Create a new branch from main"""
        try:
            repo = GitService.get_repository(project_id)
            if not repo:
                return {
                    "success": False,
                    "error": f"Project {project_id} is not a Git repository"
                }
            
            # Check if branch exists
            if branch_name in [branch.name for branch in repo.branches]:
                return {
                    "success": True,
                    "message": f"Branch '{branch_name}' already exists",
                    "already_exists": True
                }
            
            # Create and checkout new branch from main
            main_branch = repo.heads.main
            repo.create_head(branch_name, main_branch)
            
            logger.info(f"Created branch '{branch_name}' in project {project_id}")
            
            return {
                "success": True,
                "message": f"Branch '{branch_name}' created successfully",
                "already_exists": False
            }
            
        except Exception as e:
            logger.error(f"Error creating branch {branch_name}: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def switch_branch(project_id: str, branch_name: str) -> Dict[str, Any]:
        """Switch to an existing branch"""
        try:
            repo = GitService.get_repository(project_id)
            if not repo:
                return {
                    "success": False,
                    "error": f"Project {project_id} is not a Git repository"
                }
            
            # Check if branch exists
            if branch_name not in [branch.name for branch in repo.branches]:
                return {
                    "success": False,
                    "error": f"Branch '{branch_name}' does not exist"
                }
            
            # Switch to branch
            repo.heads[branch_name].checkout()
            
            return {
                "success": True,
                "message": f"Switched to branch '{branch_name}'"
            }
            
        except Exception as e:
            logger.error(f"Error switching to branch {branch_name}: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    @staticmethod
    def list_chat_branches(project_id: str) -> List[Dict[str, Any]]:
        """List all chat branches (user/default/*) with metadata"""
        try:
            repo = GitService.get_repository(project_id)
            if not repo:
                return []
            
            chat_branches = []
            
            for branch in repo.branches:
                # Only include chat branches
                if branch.name.startswith("user/default/"):
                    try:
                        last_commit = branch.commit
                        
                        # Extract session number from branch name
                        session_number = int(branch.name.split("/")[-1])
                        
                        chat_branches.append({
                            "branch_name": branch.name,
                            "session_number": session_number,
                            "last_commit_date": last_commit.committed_datetime.isoformat(),
                            "last_commit_message": last_commit.message.strip()
                        })
                    except Exception as e:
                        logger.warning(f"Error processing branch {branch.name}: {str(e)}")
            
            # Sort by session number
            chat_branches.sort(key=lambda x: x["session_number"], reverse=True)
            
            return chat_branches
            
        except Exception as e:
            logger.error(f"Error listing chat branches: {str(e)}")
            return []
    
    @staticmethod
    def delete_branch(project_id: str, branch_name: str) -> Dict[str, Any]:
        """Delete a branch (except main)"""
        try:
            repo = GitService.get_repository(project_id)
            if not repo:
                return {
                    "success": False,
                    "error": f"Project {project_id} is not a Git repository"
                }
            
            # Cannot delete main branch
            if branch_name == "main":
                return {
                    "success": False,
                    "error": "Cannot delete main branch"
                }
            
            # Cannot delete current branch
            if repo.active_branch.name == branch_name:
                # Switch to main first
                repo.heads.main.checkout()
            
            # Delete branch
            repo.delete_head(branch_name, force=True)
            
            return {
                "success": True,
                "message": f"Branch '{branch_name}' deleted successfully"
            }
            
        except Exception as e:
            logger.error(f"Error deleting branch {branch_name}: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }

================
File: genbase/server/src/routers/__Init__.py
================
"""
Routers package
"""

================
File: genbase/server/src/routers/groups.py
================
"""
FastAPI router for group operations
"""
from fastapi import APIRouter, HTTPException, Path as PathParam

from src.schemas.api import GroupListResponse, GroupResponse, CreateGroupRequest
from ..logger import logger
from ..services.project_service import ProjectService
from ..services.group_service import GroupService


router = APIRouter(
    prefix="/projects/{project_id}/groups",
    tags=["groups"]
)


@router.get("", response_model=GroupListResponse)
async def list_groups(project_id: str = PathParam(..., title="Project ID")):
    """List all groups in a project"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        groups = GroupService.list_groups(project_id)
        return GroupListResponse(
            success=True,
            data=groups
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing groups: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{group_path:path}", response_model=GroupResponse)
async def get_group(
    project_id: str = PathParam(..., title="Project ID"),
    group_path: str = PathParam(..., title="Group path")
):
    """Get group details"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        group = GroupService.get_group(project_id, group_path)
        if not group:
            raise HTTPException(status_code=404, detail=f"Group not found: {group_path}")
        
        return GroupResponse(
            success=True,
            data=group
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting group: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("", response_model=GroupResponse)
async def create_group(
    request: CreateGroupRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """Create a new group"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        group = GroupService.create_group(
            project_id=project_id,
            name=request.name,
            parent_path=request.parent_path
        )
        
        return GroupResponse(
            success=True,
            message=f"Group '{request.name}' created successfully",
            data=group
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating group: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: genbase/server/src/routers/projects.py
================
"""
FastAPI router for project operations
"""
import shutil
import os
from fastapi import APIRouter, HTTPException, Path as PathParam, Body
from typing import List, Dict, Any
from pydantic import BaseModel, validator

from src.schemas.api import ProjectListResponse, ProjectResponse, CreateProjectRequest
from ..logger import logger
from ..services.project_service import ProjectService


router = APIRouter(
    prefix="/projects",
    tags=["projects"]
)


@router.get("", response_model=ProjectListResponse)
async def list_projects():
    """List all projects"""
    try:
        projects = ProjectService.list_projects()
        return ProjectListResponse(
            success=True,
            data=projects
        )
    except Exception as e:
        logger.error(f"Error listing projects: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{project_id}", response_model=ProjectResponse)
async def get_project(project_id: str = PathParam(..., title="Project ID")):
    """Get project details"""
    try:
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        return ProjectResponse(
            success=True,
            data=project
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting project: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("", response_model=ProjectResponse)
async def create_project(request: CreateProjectRequest = Body(...)):
    """Create a new project"""
    try:
        # Validate project ID
        if not request.id.isalnum() and not all(c in (request.id + '-_') for c in request.id):
            raise HTTPException(
                status_code=400, 
                detail="Project ID must contain only alphanumeric characters, hyphens, and underscores"
            )
        
        # Check if project already exists
        existing_project = ProjectService.get_project(request.id)
        if existing_project:
            raise HTTPException(
                status_code=409,
                detail=f"Project with ID '{request.id}' already exists"
            )
        
        # Create the project
        project = ProjectService.create_project(request.id)
        
        return ProjectResponse(
            success=True,
            message=f"Project '{request.id}' created successfully",
            data=project
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating project: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: genbase/server/src/services/__init__.py
================
"""
Services package
"""

================
File: genbase/server/src/database.py
================
"""
Database connection and session management
"""
import os
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Get the database URL from environment variables
DATABASE_URL = os.getenv("DATABASE_URL")
if not DATABASE_URL:
    raise ValueError("DATABASE_URL environment variable is not set")

# Create database engine
engine = create_engine(DATABASE_URL)

# Create session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create base class for models
Base = declarative_base()


def get_db():
    """
    Get database session
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

================
File: genbase/server/src/logger.py
================
"""
Simple console logging configuration using Loguru
"""
import sys
import os
from loguru import logger as loguru_logger


# Configure loguru
def setup_logging():
    """Setup and configure Loguru console logging"""
    # Get log level from environment variable or use INFO as default
    log_level = os.getenv("LOG_LEVEL", "INFO")
    
    # Remove default logger
    loguru_logger.remove()

    # Standard format for console logging
    log_format = (
        "<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | "
        "<level>{level: <8}</level> | "
        "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
        "<level>{message}</level>"
    )

    # Add console handler
    loguru_logger.add(
        sys.stderr,
        format=log_format,
        level=log_level,
        colorize=True,
        backtrace=True,  # Detailed exception information
        diagnose=True,   # Show variables in exceptions
    )

    return loguru_logger


# Create and configure logger
logger = setup_logging()

================
File: genbase/server/src/models.py
================
"""
SQLAlchemy models
"""
from typing import Any, Dict
import litellm
from sqlalchemy import JSON, Column, Integer, String, Boolean, DateTime, ForeignKey, Text
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func

from .database import Base

from litellm import Message



class ChatMessage(Base):
    """
    Chat message model storing messages in LiteLLM format
    """
    __tablename__ = "chat_messages"

    id = Column(Integer, primary_key=True, index=True)
    
    # Session identification
    project_id = Column(String, nullable=False, index=True)
    session_id = Column(String, nullable=False, index=True)  # Git branch name
    
    # Timestamp
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    
    # LiteLLM format fields
    role = Column(String, nullable=False)  # "user", "assistant", "system", "tool"
    content = Column(Text, nullable=True)  # Main message content
    
    # Tool-related fields (JSON format)
    tool_calls = Column(JSON, nullable=True)  # For assistant messages with tool calls
    tool_call_id = Column(String, nullable=True)  # For tool response messages
    name = Column(String, nullable=True)  # Tool name for tool messages
    
    # Additional LiteLLM fields
    reasoning_content = Column(Text, nullable=True)  # For o1 models
    annotations = Column(JSON, nullable=True)  # Citations, etc.
    
    
    def to_litellm_format(self) -> Dict[str, Any]:
        """Convert to LiteLLM message format"""
        # Start with required fields
        message = {
            "role": self.role,
            "content": self.content
        }
        
        # Add optional fields if they exist
        if self.tool_calls is not None:
            message["tool_calls"] = self.tool_calls
            
        if self.tool_call_id is not None:
            message["tool_call_id"] = self.tool_call_id
            
        if self.name is not None:
            message["name"] = self.name
            
        if self.reasoning_content is not None:
            message["reasoning_content"] = self.reasoning_content
            
        if self.annotations is not None:
            message["annotations"] = self.annotations
            
        
        return message

================
File: genbase/server/src/routers/operations.py
================
"""
FastAPI router for TF operations
"""
from fastapi import APIRouter, HTTPException, Path as PathParam, Query, Body
from pydantic import BaseModel

from src.schemas.api import PlanResponse, ApplyResponse, DestroyResponse, StateResponse
from ..logger import logger
from ..services.project_service import ProjectService
from ..services.workspace_service import WorkspaceService
from ..services.tf_service import TofuService


# Define the request body model for operations
class OperationRequest(BaseModel):
    workspace: str = WorkspaceService.DEFAULT_WORKSPACE


router = APIRouter(
    prefix="/projects/{project_id}/operations",
    tags=["operations"]
)


@router.post("/plan", response_model=PlanResponse)
async def run_plan(
    request: OperationRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """Run TF plan at the project root"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        result = TofuService.run_plan(project_id, request.workspace)
        
        if not result.get("success", False):
            return PlanResponse(
                success=False,
                message="Plan failed",
                data=result
            )
        
        return PlanResponse(
            success=True,
            message="Plan completed successfully",
            data=result
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error running plan: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/apply", response_model=ApplyResponse)
async def run_apply(
    request: OperationRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """Apply TF plan at the project root"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        result = TofuService.run_apply(project_id, request.workspace)
        
        if not result.get("success", False):
            return ApplyResponse(
                success=False,
                message="Apply failed",
                data=result
            )
        
        return ApplyResponse(
            success=True,
            message="Apply completed successfully",
            data=result
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error running apply: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/destroy", response_model=DestroyResponse)
async def run_destroy(
    request: OperationRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """Destroy TF resources at the project root"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        result = TofuService.run_destroy(project_id, request.workspace)
        
        if not result.get("success", False):
            return DestroyResponse(
                success=False,
                message="Destroy failed",
                data=result
            )
        
        return DestroyResponse(
            success=True,
            message="Destroy completed successfully",
            data=result
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error running destroy: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/state", response_model=StateResponse)
async def get_state(
    project_id: str = PathParam(..., title="Project ID"),
    workspace: str = Query(WorkspaceService.DEFAULT_WORKSPACE, title="Workspace name"),
    refresh: bool = Query(False, title="Refresh state")
):
    """Get TF state at the project root"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        result = TofuService.get_state(project_id, workspace=workspace, refresh=refresh)
        
        if not result.get("success", False):
            return StateResponse(
                success=False,
                message="Failed to get state",
                data=result
            )
        
        return StateResponse(
            success=True,
            message="State retrieved successfully",
            data=result
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting state: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: genbase/server/src/routers/variables.py
================
"""
FastAPI router for variable operations
"""
from fastapi import APIRouter, HTTPException, Path as PathParam, Query, Body
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field, validator
from enum import Enum

from src.schemas.api import VariableListResponse, VariableResponse
from ..logger import logger
from ..services.project_service import ProjectService
from ..services.variable_service import VariableService
from ..services.workspace_service import WorkspaceService


# Variable type enum
class VariableType(str, Enum):
    """Variable type enum"""
    STRING = "string"
    NUMBER = "number"
    BOOL = "boolean"
    LIST = "list"
    MAP = "map"


# Variable request model
class VariableRequest(BaseModel):
    """Create/update variable request"""
    name: str
    value: Any
    description: Optional[str] = None
    is_secret: bool = False
    type: VariableType = VariableType.STRING
    workspace: Optional[str] = None
    
    @validator("name")
    def validate_name(cls, v):
        if not v or not v.isidentifier():
            raise ValueError(f"Invalid variable name: {v}. Must be a valid Terraform identifier.")
        return v


router = APIRouter(
    prefix="/projects/{project_id}/variables",
    tags=["variables"]
)


@router.get("", response_model=VariableListResponse)
async def list_variables(
    project_id: str = PathParam(..., title="Project ID"),
    workspace: Optional[str] = Query(None, title="Workspace name")
):
    """
    List all variables in a project for a specific workspace
    
    Variables are managed at the project level only.
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        # Get variables from the project
        try:
            variables = VariableService.list_variables(project_id, workspace)
            
            return VariableListResponse(
                success=True,
                data=variables
            )
        except ValueError as e:
            raise HTTPException(status_code=404, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing variables: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{variable_name}", response_model=VariableResponse)
async def get_variable(
    variable_name: str,
    project_id: str = PathParam(..., title="Project ID"),
    workspace: Optional[str] = Query(None, title="Workspace name")
):
    """Get variable details"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        # Get the variable
        try:
            variable = VariableService.get_variable(project_id, variable_name, workspace)
            if not variable:
                raise HTTPException(status_code=404, detail=f"Variable not found: {variable_name}")
            
            return VariableResponse(
                success=True,
                data=variable
            )
        except ValueError as e:
            raise HTTPException(status_code=404, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting variable: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("", response_model=VariableResponse)
async def create_variable(
    request: VariableRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """Create a new variable at the project level"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        # Create the variable
        try:
            variable = VariableService.create_or_update_variable(
                project_id=project_id,
                name=request.name,
                value=request.value,
                is_secret=request.is_secret,
                description=request.description,
                workspace=request.workspace
            )
            
            workspace_info = f" in workspace '{request.workspace}'" if request.workspace else ""
            
            return VariableResponse(
                success=True,
                message=f"Variable '{request.name}' created successfully{workspace_info}",
                data=variable
            )
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating variable: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/{variable_name}", response_model=VariableResponse)
async def update_variable(
    request: VariableRequest,
    variable_name: str,
    project_id: str = PathParam(..., title="Project ID")
):
    """Update a variable at the project level"""
    try:
        # Check if variable name in path matches request body
        if variable_name != request.name:
            raise HTTPException(
                status_code=400, 
                detail=f"Variable name in path ({variable_name}) doesn't match request body ({request.name})"
            )
        
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        # Check if variable exists and update it
        try:
            existing_var = VariableService.get_variable(project_id, variable_name, request.workspace)
            if not existing_var:
                raise HTTPException(status_code=404, detail=f"Variable not found: {variable_name}")
            
            variable = VariableService.create_or_update_variable(
                project_id=project_id,
                name=request.name,
                value=request.value,
                is_secret=request.is_secret,
                description=request.description,
                workspace=request.workspace
            )
            
            workspace_info = f" in workspace '{request.workspace}'" if request.workspace else ""
            
            return VariableResponse(
                success=True,
                message=f"Variable '{request.name}' updated successfully{workspace_info}",
                data=variable
            )
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating variable: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/{variable_name}", response_model=VariableResponse)
async def delete_variable(
    variable_name: str,
    project_id: str = PathParam(..., title="Project ID"),
    workspace: Optional[str] = Query(None, title="Workspace name")
):
    """Delete a variable at the project level"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        # Check if variable exists and delete it
        try:
            existing_var = VariableService.get_variable(project_id, variable_name, workspace)
            if not existing_var:
                raise HTTPException(status_code=404, detail=f"Variable not found: {variable_name}")
            
            success = VariableService.delete_variable(project_id, variable_name, workspace)
            
            if not success:
                raise HTTPException(status_code=500, detail=f"Failed to delete variable: {variable_name}")
            
            workspace_info = f" from workspace '{workspace}'" if workspace else ""
            
            return VariableResponse(
                success=True,
                message=f"Variable '{variable_name}' deleted successfully{workspace_info}",
                data={}
            )
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting variable: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: genbase/server/src/routers/workspaces.py
================
"""
FastAPI router for workspace operations
"""
from fastapi import APIRouter, HTTPException, Path as PathParam, Body
from pydantic import BaseModel
from typing import List, Dict, Any, Optional

from src.schemas.api import WorkspaceListResponse, WorkspaceResponse
from ..logger import logger
from ..services.project_service import ProjectService
from ..services.workspace_service import WorkspaceService


# Workspace request model
class WorkspaceRequest(BaseModel):
    """Create workspace request"""
    name: str
    
    class Config:
        schema_extra = {
            "example": {
                "name": "dev"
            }
        }


router = APIRouter(
    prefix="/projects/{project_id}/workspaces",
    tags=["workspaces"]
)


@router.get("", response_model=WorkspaceListResponse)
async def list_workspaces(
    project_id: str = PathParam(..., title="Project ID")
):
    """
    List all workspaces in a project
    
    Workspaces are managed at the project level.
    """
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        try:
            workspaces = WorkspaceService.list_workspaces(project_id)
            
            return WorkspaceListResponse(
                success=True,
                data=workspaces
            )
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing workspaces: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("", response_model=WorkspaceResponse)
async def create_workspace(
    request: WorkspaceRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """Create a new workspace at the project level"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        try:
            result = WorkspaceService.create_workspace(project_id, request.name)
            
            # Check if the workspace already existed
            if not result.get("success", True):
                raise HTTPException(status_code=400, detail=result.get("error", "Failed to create workspace"))
                
            if result.get("already_exists", False):
                return WorkspaceResponse(
                    success=True,
                    message=f"Workspace '{request.name}' already exists",
                    data=result
                )
            
            return WorkspaceResponse(
                success=True,
                message=f"Workspace '{request.name}' created successfully",
                data=result
            )
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating workspace: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/select", response_model=WorkspaceResponse)
async def select_workspace(
    request: WorkspaceRequest,
    project_id: str = PathParam(..., title="Project ID")
):
    """Select (switch to) a workspace at the project level"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        try:
            result = WorkspaceService.select_workspace(project_id, request.name)
            
            # Check if there was an error
            if not result.get("success", True):
                raise HTTPException(status_code=400, detail=result.get("error", "Failed to select workspace"))
                
            # Check if the workspace was already selected
            if result.get("already_selected", False):
                return WorkspaceResponse(
                    success=True,
                    message=f"Workspace '{request.name}' is already selected",
                    data=result
                )
            
            return WorkspaceResponse(
                success=True,
                message=f"Switched to workspace '{request.name}' successfully",
                data=result
            )
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error selecting workspace: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/{workspace_name}", response_model=WorkspaceResponse)
async def delete_workspace(
    workspace_name: str,
    project_id: str = PathParam(..., title="Project ID")
):
    """Delete a workspace at the project level"""
    try:
        # Check if project exists
        project = ProjectService.get_project(project_id)
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        
        try:
            # Cannot delete default workspace
            if workspace_name == WorkspaceService.DEFAULT_WORKSPACE:
                raise HTTPException(
                    status_code=400, 
                    detail="Cannot delete the default workspace"
                )
                
            result = WorkspaceService.delete_workspace(project_id, workspace_name)
            
            # Check if there was an error
            if not result.get("success", True):
                raise HTTPException(status_code=400, detail=result.get("error", "Failed to delete workspace"))
                
            # Check if the workspace was already deleted
            if result.get("already_deleted", False):
                return WorkspaceResponse(
                    success=True,
                    message=f"Workspace '{workspace_name}' does not exist or is already deleted",
                    data=result
                )
            
            return WorkspaceResponse(
                success=True,
                message=f"Workspace '{workspace_name}' deleted successfully",
                data=result
            )
        except ValueError as e:
            raise HTTPException(status_code=400, detail=str(e))
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting workspace: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

================
File: genbase/server/src/schemas/api.py
================
"""
Pydantic schemas for API validation
"""
from enum import Enum
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Any, Optional


# Base response model
class ResponseBase(BaseModel):
    """Base response model"""
    success: bool = True
    message: Optional[str] = None


# Error response model
class ErrorResponse(ResponseBase):
    """Error response model"""
    success: bool = False
    error: Dict[str, Any] = Field(default_factory=dict)


class ResourceStatusResponse(ResponseBase):
    """Resource status response"""
    data: Dict[str, Any] = Field(default_factory=dict)


class ProjectCodeResponse(ResponseBase):
    """Project code response"""
    data: Dict[str, Any] = Field(default_factory=dict)


# Project schemas
class ProjectListResponse(ResponseBase):
    """Project list response"""
    data: List[Dict[str, Any]] = Field(default_factory=list)


class ProjectResponse(ResponseBase):
    """Project response"""
    data: Dict[str, Any] = Field(default_factory=dict)

class CreateProjectRequest(BaseModel):
    """Create project request"""
    id: str
    
    @validator("id")
    def validate_id(cls, v):
        if not v or not v.strip():
            raise ValueError("Project ID cannot be empty")
        if len(v) > 64:
            raise ValueError("Project ID cannot exceed 64 characters")
        if not all(c.isalnum() or c in "-_" for c in v):
            raise ValueError("Project ID must contain only alphanumeric characters, hyphens, and underscores")
        return v.strip()

# Group schemas
class CreateGroupRequest(BaseModel):
    """Create group request"""
    name: str
    parent_path: str = ""
    
    @validator("name")
    def validate_name(cls, v):
        if not v or "/" in v or v in [".", ".."]:
            raise ValueError(f"Invalid group name: {v}")
        return v
    
    @validator("parent_path")
    def validate_parent_path(cls, v):
        if v:
            v = v.strip("/")
            # Ensure no directory traversal
            if ".." in v:
                raise ValueError("Directory traversal not allowed")
        return v


class GroupListResponse(ResponseBase):
    """Group list response"""
    data: List[Dict[str, Any]] = Field(default_factory=list)


class GroupResponse(ResponseBase):
    """Group response"""
    data: Dict[str, Any] = Field(default_factory=dict)


# TF operation schemas
class PlanResponse(ResponseBase):
    """Plan response"""
    data: Dict[str, Any] = Field(default_factory=dict)


class ApplyResponse(ResponseBase):
    """Apply response"""
    data: Dict[str, Any] = Field(default_factory=dict)


class DestroyResponse(ResponseBase):
    """Destroy response"""
    data: Dict[str, Any] = Field(default_factory=dict)


class StateResponse(ResponseBase):
    """State response"""
    data: Dict[str, Any] = Field(default_factory=dict) 














# Variable schemas
class VariableType(str, Enum):
    """Variable type enum"""
    STRING = "string"
    NUMBER = "number"
    BOOL = "boolean"
    LIST = "list"
    MAP = "map"


class VariableRequest(BaseModel):
    """Create/update variable request"""
    name: str
    value: Any
    description: Optional[str] = None
    is_secret: bool = False
    type: VariableType = VariableType.STRING
    
    @validator("name")
    def validate_name(cls, v):
        if not v or not v.isidentifier():
            raise ValueError(f"Invalid variable name: {v}. Must be a valid Terraform identifier.")
        return v


class VariableListResponse(ResponseBase):
    """Variable list response"""
    data: List[Dict[str, Any]] = Field(default_factory=list)


class VariableResponse(ResponseBase):
    """Variable response"""
    data: Dict[str, Any] = Field(default_factory=dict)




# Workspace schemas
class WorkspaceListResponse(ResponseBase):
    """Workspace list response"""
    data: List[Dict[str, Any]] = Field(default_factory=list)


class WorkspaceResponse(ResponseBase):
    """Workspace response"""
    data: Dict[str, Any] = Field(default_factory=dict)



# Code response schemas (add these to the existing schemas/api.py file)

class CodeResponse(ResponseBase):
    """Code parsing response"""
    data: Dict[str, Any] = Field(default_factory=dict)


class CodeStructureResponse(ResponseBase):
    """Code structure response"""
    data: Dict[str, Any] = Field(default_factory=dict)



class ChatSessionResponse(ResponseBase):
    """Chat session response"""
    data: Dict[str, Any] = Field(default_factory=dict)


class ChatSessionListResponse(ResponseBase):
    """Chat session list response"""
    data: List[Dict[str, Any]] = Field(default_factory=list)


class ChatMessageResponse(ResponseBase):
    """Chat message response"""
    data: Dict[str, Any] = Field(default_factory=dict)


class ChatMessageListResponse(ResponseBase):
    """Chat message list response"""
    data: List[Dict[str, Any]] = Field(default_factory=list)

================
File: genbase/server/src/services/group_service.py
================
"""
Service for managing groups (directories) within TF projects
"""
import os
from pathlib import Path
from typing import List, Dict, Optional

from ..logger import logger
from .project_service import ProjectService


class GroupService:
    """
    Service for managing groups within TF projects
    
    Note: Groups are just organizational directories for Terraform files.
    They don't represent independent Terraform execution contexts.
    All Terraform operations are performed at the project root level.
    """
    
    # Directories to ignore when listing groups
    IGNORED_DIRECTORIES = [
        ".terraform",
        ".git",
        "__pycache__",
        "node_modules",
        ".vscode",
        ".idea",
        "terraform.tfstate.d",
    ]
    
    @staticmethod
    def get_group_path(project_id: str, group_path: str) -> Path:
        """Get the absolute path to a group directory"""
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        # If group_path is empty, return the infrastructure directory
        if not group_path:
            return infra_path
        
        # Normalize path to avoid directory traversal
        norm_path = os.path.normpath(group_path)
        if norm_path.startswith("..") or norm_path.startswith("/"):
            raise ValueError(f"Invalid group path: {group_path}")
        
        return infra_path / norm_path
    
    @staticmethod
    def list_groups(project_id: str) -> List[Dict]:
        """
        List all groups in a project
        
        Groups are just organizational directories and don't affect
        Terraform execution context.
        """
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            logger.warning(f"Infrastructure directory not found for project: {project_id}")
            return []
        
        groups = []
        for root, dirs, files in os.walk(infra_path):
            # Modify dirs in-place to skip ignored directories
            dirs[:] = [d for d in dirs if d not in GroupService.IGNORED_DIRECTORIES]
            
            root_path = Path(root)
            
            # Skip the infrastructure root itself
            if root_path == infra_path:
                continue
            
            # Get path relative to infrastructure dir
            rel_path = root_path.relative_to(infra_path)
            
            # Get parent path (empty string if direct child of infrastructure)
            parent_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""
            
            # Count only non-hidden files
            visible_files = [f for f in files if not f.startswith('.')]
            
            groups.append({
                "name": rel_path.name,
                "path": str(rel_path),
                "parent_path": parent_path,
                "file_count": len(visible_files)
            })
        
        return groups
    
    @staticmethod
    def get_group(project_id: str, group_path: str) -> Optional[Dict]:
        """
        Get group details
        
        Groups are just organizational directories. All Terraform
        operations happen at the project level.
        """
        try:
            path = GroupService.get_group_path(project_id, group_path)
            infra_path = ProjectService.get_infrastructure_path(project_id)
            
            if not path.exists() or not path.is_dir():
                return None
            
            # Check if this is an ignored directory
            if path.name in GroupService.IGNORED_DIRECTORIES:
                return None
                
            # Count files in this group (exclude hidden files)
            files = [f for f in path.iterdir() if f.is_file() and not f.name.startswith('.')]
            tf_files = [f for f in files if f.suffix == ".tf"]
            
            # If it's the infrastructure root, special case
            if path == infra_path:
                return {
                    "name": "infrastructure",
                    "path": "",
                    "parent_path": None,
                    "is_root": True,
                    "file_count": len(files),
                    "tf_file_count": len(tf_files),
                    "files": [f.name for f in files]
                }
                
            # For normal groups
            rel_path = path.relative_to(infra_path)
            parent_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""
            
            return {
                "name": path.name,
                "path": group_path,
                "parent_path": parent_path,
                "is_root": False,
                "file_count": len(files),
                "tf_file_count": len(tf_files),
                "files": [f.name for f in files]
            }
        except ValueError as e:
            logger.error(f"Error getting group: {str(e)}")
            return None

    @staticmethod
    def create_group(project_id: str, name: str, parent_path: str = "") -> Dict:
        """
        Create a new group (directory) for organizing Terraform files
        
        Note: This just creates a directory for organization purposes.
        All Terraform operations will still be performed at the project root.
        """
        # Validate group name
        if not name or "/" in name or name in [".", ".."]:
            raise ValueError(f"Invalid group name: {name}")
            
        # Prevent reserved keywords
        if name.lower() == "operations":
            raise ValueError("Cannot create a group named 'operations' as it is a reserved keyword")
            
        # Check if this is an ignored directory name
        if name in GroupService.IGNORED_DIRECTORIES:
            raise ValueError(f"Cannot create a group with reserved name: {name}")
        
        # Get parent directory
        parent_dir = GroupService.get_group_path(project_id, parent_path)
        
        # Check if parent exists
        if not parent_dir.exists() or not parent_dir.is_dir():
            raise ValueError(f"Parent path does not exist: {parent_path}")
        
        # Create the new group
        new_group_path = parent_dir / name
        
        # Check if it already exists
        if new_group_path.exists():
            raise ValueError(f"Group already exists: {name}")
        
        # Create the directory
        new_group_path.mkdir(parents=False, exist_ok=False)
        logger.info(f"Created group '{name}' in project '{project_id}', parent path: '{parent_path}'")
        
        # Calculate the relative path from infrastructure
        infra_path = ProjectService.get_infrastructure_path(project_id)
        rel_path = new_group_path.relative_to(infra_path)
        
        return {
            "name": name,
            "path": str(rel_path),
            "parent_path": parent_path,
            "is_root": False,
            "file_count": 0
        }

================
File: genbase/server/src/services/project_service.py
================
# Complete project_service.py update with Git integration

"""
Service for managing TF projects with Git integration
"""
import os
import shutil
from pathlib import Path
from typing import List, Dict, Optional

from ..config import config
from ..logger import logger


class ProjectService:
    """Service for managing TF projects with Git integration"""
    
    @staticmethod
    def get_project_path(project_id: str) -> Path:
        """Get the path to a project directory"""
        base_dir = Path(config.BASE_DIR)
        return base_dir / "projects" / project_id
    
    @staticmethod
    def get_infrastructure_path(project_id: str) -> Path:
        """Get the path to a project's infrastructure directory"""
        project_path = ProjectService.get_project_path(project_id)
        return project_path / "infrastructure"
    
    @staticmethod
    def list_projects() -> List[Dict]:
        """List all projects"""
        base_dir = Path(config.BASE_DIR)
        projects_dir = base_dir / "projects"
        
        if not projects_dir.exists():
            logger.warning(f"Projects directory not found: {projects_dir}")
            return []
        
        projects = []
        for item in projects_dir.iterdir():
            if item.is_dir():
                # Check if it has an infrastructure directory
                infra_dir = item.joinpath("infrastructure")
                if infra_dir.exists() and infra_dir.is_dir():
                    projects.append({
                        "id": item.name,
                        "path": str(item)
                    })
        
        return projects
    
    @staticmethod
    def get_project(project_id: str) -> Optional[Dict]:
        """Get project details"""
        project_path = ProjectService.get_project_path(project_id)
        infra_path = project_path / "infrastructure"
        
        if not infra_path.exists() or not infra_path.is_dir():
            return None
        
        # Get some basic statistics
        group_count = 0
        file_count = 0
        
        for root, dirs, files in os.walk(infra_path):
            rel_path = Path(root).relative_to(infra_path)
            if str(rel_path) != ".":
                group_count += 1
            file_count += len(files)
        
        return {
            "id": project_id,
            "path": str(project_path),
            "infrastructure_path": str(infra_path),
            "group_count": group_count,
            "file_count": file_count
        }
    
    @staticmethod
    def create_project(project_id: str) -> Dict:
        """Create a new project with Git initialization"""
        from .git_service import GitService  # Import here to avoid circular imports
        
        project_path = ProjectService.get_project_path(project_id)
        infra_path = project_path / "infrastructure"
        modules_path = project_path / "modules"
        
        # Check if project directory already exists
        if project_path.exists():
            raise ValueError(f"Project directory already exists: {project_path}")
        
        try:
            # Create project directory structure
            project_path.mkdir(parents=True, exist_ok=False)
            infra_path.mkdir(parents=False, exist_ok=False)
            modules_path.mkdir(parents=False, exist_ok=False)
            
            # Create default Terraform configuration file
            main_tf = infra_path / "main.tf"
            with open(main_tf, "w") as f:
                f.write('# Genbase project main configuration\n\n')
            
            # Create terraform.tfvars.json with empty object
            tfvars_file = infra_path / "terraform.tfvars.json"
            with open(tfvars_file, "w") as f:
                f.write('{\n}\n')
            
            # Initialize Git repository
            git_result = GitService.init_repository(project_id)
            if not git_result.get("success", False):
                logger.warning(f"Failed to initialize Git repository: {git_result.get('error', 'Unknown error')}")
            else:
                logger.info(f"Git repository initialized for project: {project_id}")
            
            logger.info(f"Created new project: {project_id}")
            
            # Return the project details
            return {
                "id": project_id,
                "path": str(project_path),
                "infrastructure_path": str(infra_path),
                "group_count": 0,
                "file_count": 2,  # main.tf and terraform.tfvars.json
                "git_initialized": git_result.get("success", False)
            }
            
        except Exception as e:
            # Clean up on failure
            if project_path.exists():
                shutil.rmtree(project_path)
            logger.error(f"Failed to create project {project_id}: {str(e)}")
            raise

================
File: genbase/server/src/services/tf_service.py
================
"""
Service for executing TF CLI commands
"""
import json
import subprocess
import os
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List

from ..logger import logger
from .project_service import ProjectService
from .variable_service import VariableService
from .workspace_service import WorkspaceService


class TofuService:
    """
    Service for executing TF CLI commands
    
    All Terraform commands are executed at the project root level.
    """
    
    @staticmethod
    def _run_command(cmd: list, project_id: str) -> Tuple[int, str, str]:
        """Run a command at the project root and return exit code, stdout, and stderr"""
        # Always run commands at the project infrastructure root
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        logger.debug(f"Running command: {' '.join(cmd)} in {infra_path}")
        
        process = subprocess.Popen(
            cmd,
            cwd=str(infra_path),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        stdout, stderr = process.communicate()
        exit_code = process.returncode
        
        if exit_code != 0:
            logger.warning(f"Command failed with exit code {exit_code}: {stderr}")
        
        return exit_code, stdout, stderr
    
    @staticmethod
    def run_plan(project_id: str, workspace: Optional[str] = None) -> Dict[str, Any]:
        """Run tf plan at the project root"""
        # Default to default workspace if not specified
        if workspace is None:
            workspace = WorkspaceService.DEFAULT_WORKSPACE
            
        # Get the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            raise ValueError(f"Infrastructure path does not exist for project: {project_id}")
        
        # Check if tf files exist in the directory
        tf_files = list(infra_path.glob("*.tf"))
        if not tf_files:
            logger.warning(f"No TF files found in project root for {project_id}")
        
        # Initialize if needed
        init_needed = not (infra_path / ".terraform").exists()
        if init_needed:
            logger.info(f"Running init in project {project_id}")
            init_cmd = ["tofu", "init"]
            exit_code, stdout, stderr = TofuService._run_command(init_cmd, project_id)
            if exit_code != 0:
                return {
                    "success": False,
                    "error": stderr,
                    "init_output": stdout
                }
        
        # Switch to the requested workspace if needed
        workspace_result = WorkspaceService.select_workspace(project_id, workspace)
        if not workspace_result.get("success", False):
            return {
                "success": False,
                "error": f"Failed to select workspace: {workspace}",
                "details": workspace_result.get("error", "")
            }
        
        # Get variable files for the command (now centralized)
        var_file_args = VariableService.get_var_file_paths_for_command(project_id, workspace)
        
        # Run tf plan with JSON output
        plan_file = infra_path / f"{workspace}_plan.tfplan"
        json_file = infra_path / f"{workspace}_plan.json"
        
        # Create plan file with workspace-specific variables
        plan_cmd = ["tofu", "plan", f"-out={plan_file.name}"] + var_file_args
        exit_code, plan_stdout, plan_stderr = TofuService._run_command(plan_cmd, project_id)
        
        if exit_code != 0:
            return {
                "success": False,
                "error": plan_stderr,
                "output": plan_stdout
            }
        
        # Convert plan to JSON
        json_cmd = ["tofu", "show", "-json", plan_file.name]
        exit_code, json_stdout, json_stderr = TofuService._run_command(json_cmd, project_id)
        
        if exit_code != 0:
            return {
                "success": False,
                "error": json_stderr,
                "output": json_stdout
            }
        
        # Save the JSON output to file
        try:
            with open(json_file, "w") as f:
                f.write(json_stdout)
        except Exception as e:
            logger.error(f"Failed to write plan JSON: {str(e)}")
        
        # Parse the JSON output
        try:
            plan_data = json.loads(json_stdout)
            return {
                "success": True,
                "plan": plan_data,
                "summary": TofuService._extract_plan_summary(plan_data),
                "workspace": workspace
            }
        except json.JSONDecodeError:
            logger.error("Failed to parse plan JSON output")
            return {
                "success": False,
                "error": "Failed to parse plan JSON output",
                "raw_output": json_stdout
            }
    
    @staticmethod
    def _extract_plan_summary(plan_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract summary information from plan data"""
        summary = {
            "add": 0,
            "change": 0,
            "destroy": 0
        }
        
        # Extract resource changes
        resource_changes = plan_data.get("resource_changes", [])
        for change in resource_changes:
            actions = change.get("change", {}).get("actions", [])
            if "create" in actions:
                summary["add"] += 1
            elif "update" in actions:
                summary["change"] += 1
            elif "delete" in actions:
                summary["destroy"] += 1
        
        return summary
    
    @staticmethod
    def run_apply(project_id: str, workspace: Optional[str] = None) -> Dict[str, Any]:
        """Apply the latest plan at the project root"""
        # Default to default workspace if not specified
        if workspace is None:
            workspace = WorkspaceService.DEFAULT_WORKSPACE
            
        # Get the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            raise ValueError(f"Infrastructure path does not exist for project: {project_id}")
        
        # Switch to the requested workspace if needed
        workspace_result = WorkspaceService.select_workspace(project_id, workspace)
        if not workspace_result.get("success", False):
            return {
                "success": False,
                "error": f"Failed to select workspace: {workspace}",
                "details": workspace_result.get("error", "")
            }
        
        # Check if plan file exists
        plan_file = infra_path / f"{workspace}_plan.tfplan"
        if not plan_file.exists():
            return {
                "success": False,
                "error": f"No plan file found for workspace {workspace}. Run plan first."
            }
        
        # Run tf apply
        apply_cmd = ["tofu", "apply", "-auto-approve", plan_file.name]
        exit_code, stdout, stderr = TofuService._run_command(apply_cmd, project_id)
        
        if exit_code != 0:
            return {
                "success": False,
                "error": stderr,
                "output": stdout
            }
        
        # Try to parse state after apply
        try:
            state = TofuService.get_state(project_id, workspace=workspace, refresh=False)
            return {
                "success": True,
                "output": stdout,
                "state_summary": state.get("summary", {}),
                "workspace": workspace
            }
        except Exception as e:
            logger.error(f"Failed to get state after apply: {str(e)}")
            return {
                "success": True,
                "output": stdout,
                "workspace": workspace
            }
    
    @staticmethod
    def run_destroy(project_id: str, workspace: Optional[str] = None) -> Dict[str, Any]:
        """Destroy resources defined at the project root"""
        # Default to default workspace if not specified
        if workspace is None:
            workspace = WorkspaceService.DEFAULT_WORKSPACE
            
        # Get the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            raise ValueError(f"Infrastructure path does not exist for project: {project_id}")
        
        # Switch to the requested workspace if needed
        workspace_result = WorkspaceService.select_workspace(project_id, workspace)
        if not workspace_result.get("success", False):
            return {
                "success": False,
                "error": f"Failed to select workspace: {workspace}",
                "details": workspace_result.get("error", "")
            }
        
        # Get variable files for the command (now centralized)
        var_file_args = VariableService.get_var_file_paths_for_command(project_id, workspace)
        
        # Run tf destroy with workspace-specific variables
        destroy_cmd = ["tofu", "destroy", "-auto-approve"] + var_file_args
        exit_code, stdout, stderr = TofuService._run_command(destroy_cmd, project_id)
        
        if exit_code != 0:
            return {
                "success": False,
                "error": stderr,
                "output": stdout
            }
        
        return {
            "success": True,
            "output": stdout,
            "workspace": workspace
        }
    
    @staticmethod
    def get_state(project_id: str, workspace: Optional[str] = None, refresh: bool = False) -> Dict[str, Any]:
        """Get the current state at the project root"""
        # Default to default workspace if not specified
        if workspace is None:
            workspace = WorkspaceService.DEFAULT_WORKSPACE
            
        # Get the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            raise ValueError(f"Infrastructure path does not exist for project: {project_id}")
        
        # Switch to the requested workspace if needed
        workspace_result = WorkspaceService.select_workspace(project_id, workspace)
        if not workspace_result.get("success", False):
            return {
                "success": False,
                "error": f"Failed to select workspace: {workspace}",
                "details": workspace_result.get("error", "")
            }
            
        # Build the command
        state_cmd = ["tofu", "show", "-json"]
        
        # Add refresh flag if needed
        if refresh:
            # First do a refresh with workspace-specific variables
            var_file_args = VariableService.get_var_file_paths_for_command(project_id, workspace)
            refresh_cmd = ["tofu", "refresh"] + var_file_args
            exit_code, stdout, stderr = TofuService._run_command(refresh_cmd, project_id)
            if exit_code != 0:
                return {
                    "success": False,
                    "error": stderr,
                    "output": stdout
                }
        
        # Run the state command
        exit_code, stdout, stderr = TofuService._run_command(state_cmd, project_id)
        
        if exit_code != 0:
            return {
                "success": False,
                "error": stderr,
                "output": stdout
            }
        
        # Parse the JSON output
        try:
            state_data = json.loads(stdout)
            return {
                "success": True,
                "state": state_data,
                "summary": TofuService._extract_state_summary(state_data),
                "workspace": workspace
            }
        except json.JSONDecodeError:
            logger.error("Failed to parse state JSON output")
            return {
                "success": False,
                "error": "Failed to parse state JSON output",
                "raw_output": stdout
            }
    
    @staticmethod
    def _extract_state_summary(state_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract summary information from state data"""
        summary = {
            "resource_count": 0,
            "resource_types": set(),
            "outputs": []
        }
        
        # Get resources
        resources = state_data.get("values", {}).get("root_module", {}).get("resources", [])
        summary["resource_count"] = len(resources)
        
        # Extract resource types
        for resource in resources:
            summary["resource_types"].add(resource.get("type", "unknown"))
        
        # Convert set to list for JSON serialization
        summary["resource_types"] = list(summary["resource_types"])
        
        # Get outputs
        outputs = state_data.get("values", {}).get("outputs", {})
        for name, output in outputs.items():
            summary["outputs"].append({
                "name": name,
                "type": output.get("type", "unknown")
            })
        
        return summary

================
File: genbase/server/src/services/variable_service.py
================
"""
Service for managing Terraform variables using JSON format
"""
import os
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

from ..logger import logger
from .project_service import ProjectService
from .workspace_service import WorkspaceService

class VariableService:
    """
    Service for managing Terraform variables using JSON format
    
    Variables are managed at the project level, not at the group level.
    All variable files are stored at the project root.
    """
    
    # Base file names for variables (using .tfvars.json extension)
    BASE_TFVARS_FILE = "terraform.tfvars.json"
    BASE_SECRET_TFVARS_FILE = "secrets.auto.tfvars.json"
    
    @staticmethod
    def _get_variable_file_names(workspace: Optional[str] = None) -> Tuple[str, str]:
        """Get variable file names based on workspace"""
        if not workspace or workspace == WorkspaceService.DEFAULT_WORKSPACE:
            # Default workspace uses standard file names
            return VariableService.BASE_TFVARS_FILE, VariableService.BASE_SECRET_TFVARS_FILE
        else:
            # Other workspaces use workspace-prefixed file names
            return f"{workspace}.{VariableService.BASE_TFVARS_FILE}", f"{workspace}.{VariableService.BASE_SECRET_TFVARS_FILE}"
    
    @staticmethod
    def get_variable_files(project_id: str, workspace: Optional[str] = None) -> Tuple[Path, Path]:
        """Get paths to variable files for a project"""
        # Resolve workspace if not provided
        if workspace is None:
            workspace = WorkspaceService.get_current_workspace(project_id)
            
        # Get file names based on workspace
        tfvars_filename, secret_tfvars_filename = VariableService._get_variable_file_names(workspace)
        
        # Always use the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        if not infra_path.exists() or not infra_path.is_dir():
            raise ValueError(f"Infrastructure directory not found for project: {project_id}")
        
        tfvars_path = infra_path / tfvars_filename
        secret_tfvars_path = infra_path / secret_tfvars_filename
        
        return tfvars_path, secret_tfvars_path
    
    @staticmethod
    def _load_json_file(file_path: Path) -> Dict[str, Any]:
        """Load JSON file content"""
        if not file_path.exists():
            return {}
        
        try:
            with open(file_path, 'r') as file:
                return json.load(file)
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in {file_path}: {str(e)}")
            return {}
        except Exception as e:
            logger.error(f"Error reading file {file_path}: {str(e)}")
            return {}
    
    @staticmethod
    def _write_json_file(file_path: Path, variables: Dict[str, Any]) -> bool:
        """Write variables to JSON file"""
        try:
            # Create parent directory if it doesn't exist
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Write the JSON file with nice formatting
            with open(file_path, 'w') as file:
                json.dump(variables, file, indent=2)
                
            return True
        except Exception as e:
            logger.error(f"Error writing JSON file {file_path}: {str(e)}")
            return False
    
    @staticmethod
    def list_variables(project_id: str, workspace: Optional[str] = None) -> List[Dict[str, Any]]:
        """List all variables in a project for a specific workspace"""
        tfvars_path, secret_tfvars_path = VariableService.get_variable_files(project_id, workspace)
        
        # Load variables from files
        regular_vars = VariableService._load_json_file(tfvars_path)
        secret_vars = VariableService._load_json_file(secret_tfvars_path)
        
        # Combine and format the variables
        result = []
        
        # Add regular variables
        for name, value in regular_vars.items():
            var_type = VariableService._infer_type(value)
            result.append({
                "name": name,
                "value": value,
                "type": var_type,
                "is_secret": False,
                "workspace": workspace or WorkspaceService.DEFAULT_WORKSPACE
            })
        
        # Add secret variables
        for name, value in secret_vars.items():
            var_type = VariableService._infer_type(value)
            result.append({
                "name": name,
                "value": value,
                "type": var_type,
                "is_secret": True,
                "workspace": workspace or WorkspaceService.DEFAULT_WORKSPACE
            })
        
        return result
    
    @staticmethod
    def _infer_type(value: Any) -> str:
        """Infer variable type from value"""
        if isinstance(value, bool):
            return "boolean"
        elif isinstance(value, (int, float)):
            return "number"
        elif isinstance(value, str):
            return "string"
        elif isinstance(value, list):
            return "list"
        elif isinstance(value, dict):
            return "map"
        else:
            return "string"
    
    @staticmethod
    def get_variable(project_id: str, variable_name: str, workspace: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """Get a specific variable"""
        variables = VariableService.list_variables(project_id, workspace)
        
        for var in variables:
            if var["name"] == variable_name:
                return var
                
        return None
    
    @staticmethod
    def create_or_update_variable(
        project_id: str, 
        name: str, 
        value: Any, 
        is_secret: bool = False,
        description: Optional[str] = None,
        workspace: Optional[str] = None
    ) -> Dict[str, Any]:
        """Create or update a variable at the project level"""
        # Get paths to variable files
        tfvars_path, secret_tfvars_path = VariableService.get_variable_files(project_id, workspace)
        
        # Determine which file to use
        target_path = secret_tfvars_path if is_secret else tfvars_path
        
        # Load current variables
        current_vars = VariableService._load_json_file(target_path)
        
        # Update or add the variable
        current_vars[name] = value
        
        # Write back to file
        success = VariableService._write_json_file(target_path, current_vars)
        
        if not success:
            raise ValueError(f"Failed to write variable to file")
        
        # Infer the type
        var_type = VariableService._infer_type(value)
        
        return {
            "name": name,
            "value": value,
            "type": var_type,
            "is_secret": is_secret,
            "description": description,
            "workspace": workspace or WorkspaceService.DEFAULT_WORKSPACE
        }
    
    @staticmethod
    def delete_variable(project_id: str, variable_name: str, workspace: Optional[str] = None) -> bool:
        """Delete a variable at the project level"""
        # Check if variable exists
        variable = VariableService.get_variable(project_id, variable_name, workspace)
        if not variable:
            raise ValueError(f"Variable not found: {variable_name}")
        
        # Get paths to variable files
        tfvars_path, secret_tfvars_path = VariableService.get_variable_files(project_id, workspace)
        
        # Determine which file to use
        target_path = secret_tfvars_path if variable["is_secret"] else tfvars_path
        
        # Load current variables
        current_vars = VariableService._load_json_file(target_path)
        
        # Remove the variable
        if variable_name in current_vars:
            del current_vars[variable_name]
        
        # Write back to file
        return VariableService._write_json_file(target_path, current_vars)

    @staticmethod
    def get_var_file_paths_for_command(project_id: str, workspace: Optional[str] = None) -> List[str]:
        """Get variable file paths to use in OpenTofu commands"""
        # Get variable files for both default and specified workspace
        result = []
        
        # First get default workspace files (always include these)
        default_tfvars_path, default_secret_tfvars_path = VariableService.get_variable_files(
            project_id, WorkspaceService.DEFAULT_WORKSPACE
        )
        
        # Check if default variable files exist and add them
        if default_tfvars_path.exists():
            result.append(f"-var-file={default_tfvars_path.name}")
        
        if default_secret_tfvars_path.exists():
            # Secrets should be loaded automatically because of the .auto. in the filename,
            # but we explicitly include them for clarity
            result.append(f"-var-file={default_secret_tfvars_path.name}")
        
        # If a specific workspace is requested and it's not default, add those files too
        if workspace and workspace != WorkspaceService.DEFAULT_WORKSPACE:
            workspace_tfvars_path, workspace_secret_tfvars_path = VariableService.get_variable_files(
                project_id, workspace
            )
            
            if workspace_tfvars_path.exists():
                result.append(f"-var-file={workspace_tfvars_path.name}")
            
            if workspace_secret_tfvars_path.exists():
                result.append(f"-var-file={workspace_secret_tfvars_path.name}")
        
        return result

================
File: genbase/server/src/services/workspace_service.py
================
"""
Service for managing OpenTofu workspaces within projects
"""
import os
import subprocess
from pathlib import Path
from typing import Any, List, Dict, Optional, Tuple

from ..logger import logger
from .project_service import ProjectService


class WorkspaceService:
    """
    Service for managing OpenTofu workspaces
    
    All workspace operations are performed at the project root level.
    """
    
    DEFAULT_WORKSPACE = "default"
    
    @staticmethod
    def _run_workspace_command(cmd: list, project_id: str) -> Tuple[int, str, str]:
        """Run a workspace command at the project root and return exit code, stdout, and stderr"""
        # Always run workspace commands at the project root
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        logger.debug(f"Running workspace command: {' '.join(cmd)} in {infra_path}")
        
        process = subprocess.Popen(
            cmd,
            cwd=str(infra_path),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        stdout, stderr = process.communicate()
        exit_code = process.returncode
        
        if exit_code != 0:
            logger.warning(f"Workspace command failed with exit code {exit_code}: {stderr}")
        
        return exit_code, stdout, stderr
    
    @staticmethod
    def list_workspaces(project_id: str) -> List[Dict[str, Any]]:
        """List all workspaces in a project"""
        # Get the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            raise ValueError(f"Infrastructure path does not exist for project: {project_id}")
        
        # Check if terraform is initialized
        terraform_dir = infra_path / ".terraform"
        if not terraform_dir.exists():
            # Run init first
            init_cmd = ["tofu", "init"]
            exit_code, _, stderr = WorkspaceService._run_workspace_command(init_cmd, project_id)
            if exit_code != 0:
                raise ValueError(f"Failed to initialize Terraform: {stderr}")
        
        # Get workspaces
        workspace_cmd = ["tofu", "workspace", "list"]
        exit_code, stdout, stderr = WorkspaceService._run_workspace_command(workspace_cmd, project_id)
        
        if exit_code != 0:
            raise ValueError(f"Failed to list workspaces: {stderr}")
        
        # Parse workspace output
        # Typical output format:
        #   default
        # * dev
        #   prod
        workspaces = []
        current_workspace = None
        
        for line in stdout.strip().split("\n"):
            is_current = line.startswith("*")
            workspace_name = line.strip("* ").strip()
            
            if workspace_name:
                workspace_info = {
                    "name": workspace_name,
                    "is_current": is_current
                }
                workspaces.append(workspace_info)
                
                if is_current:
                    current_workspace = workspace_name
        
        # If somehow we don't have a current workspace marked, assume default
        if not current_workspace and workspaces:
            for workspace in workspaces:
                if workspace["name"] == WorkspaceService.DEFAULT_WORKSPACE:
                    workspace["is_current"] = True
                    break
        
        return workspaces
    
    @staticmethod
    def get_current_workspace(project_id: str) -> str:
        """Get the current workspace name for a project"""
        try:
            workspaces = WorkspaceService.list_workspaces(project_id)
            
            for workspace in workspaces:
                if workspace.get("is_current", False):
                    return workspace["name"]
                    
            # If no current workspace found, assume default
            return WorkspaceService.DEFAULT_WORKSPACE
        except Exception as e:
            logger.error(f"Error getting current workspace: {str(e)}")
            # Fallback to default workspace
            return WorkspaceService.DEFAULT_WORKSPACE
    
    @staticmethod
    def create_workspace(project_id: str, workspace_name: str) -> Dict[str, Any]:
        """Create a new workspace at the project level"""
        # Validate workspace name
        if not workspace_name or "/" in workspace_name or workspace_name in [".", ".."]:
            raise ValueError(f"Invalid workspace name: {workspace_name}")
        
        # Get the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            raise ValueError(f"Infrastructure path does not exist for project: {project_id}")
        
        # Check if terraform is initialized
        terraform_dir = infra_path / ".terraform"
        if not terraform_dir.exists():
            # Run init first
            init_cmd = ["tofu", "init"]
            exit_code, _, stderr = WorkspaceService._run_workspace_command(init_cmd, project_id)
            if exit_code != 0:
                raise ValueError(f"Failed to initialize Terraform: {stderr}")
        
        # Check if workspace already exists
        workspaces = WorkspaceService.list_workspaces(project_id)
        for ws in workspaces:
            if ws["name"] == workspace_name:
                return {
                    "success": True,
                    "name": workspace_name,
                    "is_current": ws.get("is_current", False),
                    "already_exists": True
                }
        
        # Create the workspace
        create_cmd = ["tofu", "workspace", "new", workspace_name]
        exit_code, stdout, stderr = WorkspaceService._run_workspace_command(create_cmd, project_id)
        
        if exit_code != 0:
            return {
                "success": False,
                "error": f"Failed to create workspace: {stderr}"
            }
        
        return {
            "success": True,
            "name": workspace_name,
            "is_current": True,  # New workspace becomes the current one
            "already_exists": False
        }
    
    @staticmethod
    def select_workspace(project_id: str, workspace_name: str) -> Dict[str, Any]:
        """
        Select (switch to) a workspace at the project level
        
        Returns a dict with success status and workspace information.
        """
        # Get the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            return {
                "success": False,
                "error": f"Infrastructure path does not exist for project: {project_id}"
            }
        
        # Check if workspace exists
        workspaces = WorkspaceService.list_workspaces(project_id)
        workspace_exists = False
        
        for ws in workspaces:
            if ws["name"] == workspace_name:
                workspace_exists = True
                # If it's already current, return early
                if ws.get("is_current", False):
                    return {
                        "success": True,
                        "name": workspace_name,
                        "is_current": True,
                        "already_selected": True
                    }
                break
        
        # Create workspace if it doesn't exist
        if not workspace_exists:
            # For default workspace, it should already exist, so this is an error
            if workspace_name == WorkspaceService.DEFAULT_WORKSPACE:
                return {
                    "success": False,
                    "error": f"Default workspace not found. Terraform may not be initialized."
                }
            
            # Create the workspace
            create_result = WorkspaceService.create_workspace(project_id, workspace_name)
            if not create_result.get("success", False):
                return create_result
                
            return {
                "success": True,
                "name": workspace_name,
                "is_current": True,
                "already_selected": False
            }
        
        # Select the workspace
        select_cmd = ["tofu", "workspace", "select", workspace_name]
        exit_code, stdout, stderr = WorkspaceService._run_workspace_command(select_cmd, project_id)
        
        if exit_code != 0:
            return {
                "success": False,
                "error": f"Failed to select workspace: {stderr}"
            }
        
        return {
            "success": True,
            "name": workspace_name,
            "is_current": True,
            "already_selected": False
        }
    
    @staticmethod
    def delete_workspace(project_id: str, workspace_name: str) -> Dict[str, Any]:
        """Delete a workspace at the project level"""
        # Cannot delete default workspace
        if workspace_name == WorkspaceService.DEFAULT_WORKSPACE:
            return {
                "success": False,
                "error": "Cannot delete the default workspace"
            }
        
        # Get the infrastructure root path
        infra_path = ProjectService.get_infrastructure_path(project_id)
        
        if not infra_path.exists() or not infra_path.is_dir():
            return {
                "success": False,
                "error": f"Infrastructure path does not exist for project: {project_id}"
            }
        
        # Check if workspace exists and is not current
        workspaces = WorkspaceService.list_workspaces(project_id)
        workspace_exists = False
        is_current = False
        
        for ws in workspaces:
            if ws["name"] == workspace_name:
                workspace_exists = True
                is_current = ws.get("is_current", False)
                break
        
        if not workspace_exists:
            return {
                "success": True,
                "already_deleted": True
            }
        
        # Cannot delete current workspace, switch to default first
        if is_current:
            # Switch to default
            select_cmd = ["tofu", "workspace", "select", WorkspaceService.DEFAULT_WORKSPACE]
            exit_code, stdout, stderr = WorkspaceService._run_workspace_command(select_cmd, project_id)
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Failed to switch from workspace before deletion: {stderr}"
                }
        
        # Delete the workspace
        delete_cmd = ["tofu", "workspace", "delete", workspace_name]
        exit_code, stdout, stderr = WorkspaceService._run_workspace_command(delete_cmd, project_id)
        
        if exit_code != 0:
            return {
                "success": False,
                "error": f"Failed to delete workspace: {stderr}"
            }
        
        return {
            "success": True,
            "already_deleted": False
        }

================
File: genbase/server/src/config.py
================
"""
Application configuration
"""
import os
from typing import List
from pydantic import BaseModel
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

class Config(BaseModel):
    """
    Application settings
    """
    # Database settings
    DATABASE_URL: str = os.getenv("DATABASE_URL", "")
    
    # Application settings
    APP_NAME: str = "Genbase API"
    APP_VERSION: str = "0.1.0"
    APP_DESCRIPTION: str = "Genbase API Server"
    
    # API settings
    API_PREFIX: str = os.getenv("API_PREFIX", "/api/v1")

    BASE_DIR: str = '/root/development/genbase-project/genbase/test'

    CORS_ORIGINS: List[str] = [origin.strip() for origin in os.getenv("CORS_ORIGINS", "http://localhost:3000,https://console.genbase.io").split(",")]



# Create settings instance
config = Config()

================
File: genbase/server/src/main.py
================
"""
FastAPI main application file
"""
import os
from fastapi import FastAPI, Depends
from sqlalchemy.orm import Session
from sqlalchemy import text
from alembic.config import Config as AlembicConfig
from alembic import command
from pathlib import Path
from fastapi.middleware.cors import CORSMiddleware
from src.routers import chat
from src.routers import code
from src.routers import workspaces
from src.routers import variables

from .database import get_db
from .config import config
from .logger import logger
from src.routers import projects, groups, operations

# Initialize FastAPI app
app = FastAPI(
    title=config.APP_NAME,
    description=config.APP_DESCRIPTION,
    version=config.APP_VERSION,
    root_path=config.API_PREFIX,
)


app.add_middleware(
    CORSMiddleware,
    allow_origins=config.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)









# Include routers
app.include_router(projects.router)
app.include_router(groups.router)
app.include_router(operations.router)
app.include_router(variables.router)
app.include_router(workspaces.router)
app.include_router(code.router)
app.include_router(chat.router)



def run_migrations():
    """Run database migrations using Alembic"""
    try:
        logger.info("Running database migrations...")
        # Get the directory of the current file
        current_dir = Path(__file__).parent.parent
        alembic_ini_path = current_dir / "alembic.ini"
        
        if not alembic_ini_path.exists():
            logger.error(f"Alembic config not found at {alembic_ini_path}")
            raise FileNotFoundError(f"Alembic config not found at {alembic_ini_path}")
        
        # Create Alembic config
        alembic_cfg = AlembicConfig(str(alembic_ini_path))
        
        # Run the migrations
        command.upgrade(alembic_cfg, "head")
        logger.success("Database migrations completed successfully")
    except Exception as e:
        logger.error(f"Error running database migrations: {str(e)}")
        raise


@app.on_event("startup")
async def startup_event():
    """
    Execute tasks on application startup
    """
    logger.info(f"Starting {config.APP_NAME} v{config.APP_VERSION}")
    # Run database migrations
    run_migrations()
    logger.info("Application startup complete")


@app.get("/")
async def root():
    """Root endpoint"""
    logger.debug("Root endpoint called")
    return {"message": f"Welcome to {config.APP_NAME}"}


@app.get("/health")
async def health(db: Session = Depends(get_db)):
    """Health check endpoint with database connection test"""
    logger.debug("Health check endpoint called")
    try:
        # Try to execute a simple query to check database connection
        db.execute(text("SELECT 1"))
        logger.debug("Database connection successful")
        return {"status": "healthy", "database": "connected"}
    except Exception as e:
        logger.error(f"Database connection failed: {str(e)}")
        return {"status": "unhealthy", "database": str(e)}


if __name__ == "__main__":
    import uvicorn
    logger.info("Starting server directly")
    uvicorn.run("src.main:app", host="0.0.0.0", port=8000, reload=True)




================================================================
End of Codebase
================================================================
